{
  "DEFAULT_MODEL": "gemma",
  "MAX_SIZE_MB": 10,
  "HUMAN_TIMEOUT": 5,
  "SOURCE_LANGUAGE": "Simplified Chinese",
  "TARGET_LANGUAGE": "English",
  "TERMINAL_PREPEND": "{{TERMINAL}}",
  "DEFAULT_TF_PROMPT": "{{TERMINAL}} Write a summary of the following file.",
  "EMPTY_FIELD": [false, "", "", false],
  "TEMPLATES": {
    "MAIN_TL_INSTRUCTIONS": "Translate any text you're given from {{ .LanguageSource }} into {{ .LanguageTarget }}. No commentary.",
    "TERMINAL": "No markdown."
  },
  "FALLBACK_VALUES": {
    "chunkSize": "20",
    "batchSize": "4",
    "parallel": "4",
    "model": [false, ""],
    "url": "http://localhost:8080/v1/chat/completions",
    "apiKey": "",
    "temperature": [true, 1.0],
    "top_p": [true, 1.0]
  },
  "LLAMACPP_CMD": "C:\\largedrivesonly\\ai\\soft\\llamacpp\\llama-server.exe",
  "MODELS_LOCATION": "C:\\largedrivesonly\\ai\\Models\\LLM",
  "LLAMACPP_BASE_ARGS": ["--jinja"],
  "QUANTIZATION_ORDER": ["q8", "q4"],
  "PARAM_CONFIGS": {
    "online_api": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.fallback",
        "localPreset": false
      },
      "default": {
        "prompt": {
          "defSys": [false, "", "", false],
          "defPrep": [true, "{{MAIN_TL_INSTRUCTIONS}}", "user", false]
        },
        "model": {
          "delay": [false, 60],
          "llmbackend": "openai",
          "model": [false, ""],
          "temperature": [true, 1.0],
          "top_p": [true, 1.0]
        }
      }
    },
    "gprep": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.genericprep",
        "localPreset": true
      },
      "default": {
        "prompt": {
          "defSys": [false, "", "", false],
          "defPrep": [true, "{{MAIN_TL_INSTRUCTIONS}}", "user", false]
        },
        "model": {
          "delay": [false, 0.1],
          "llmbackend": "openai",
          "url": "http://localhost:8080/v1/chat/completions",
          "temperature": [true, 0.8],
          "top_p": [true, 1.0],
          "top_k": [true, 100],
          "min_p": [true, 0.0],
          "repeat_penalty": [true, 1.0],
          "model": [true, "testmodel"]
        }
      }
    },
    "gemma": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.genericprep",
        "localPreset": true
      },
      "default": {
        "prompt": {
          "defSys": [false, "", "", false],
          "defPrep": [true, "{{MAIN_TL_INSTRUCTIONS}}", "user", false]
        },
        "model": {
          "delay": [false, 0.1],
          "llmbackend": "openai",
          "url": "http://localhost:8080/v1/chat/completions",
          "temperature": [true, 0],
          "top_p": [true, 0.95],
          "top_k": [true, 64],
          "min_p": [true, 0.0],
          "repeat_penalty": [true, 1.0],
          "model": [true, "gemma"]
        }
      },
      "quantFiles": {
        "q4": {
          "file": "gemma-3-4b-it-q4_0_s.gguf",
          "fileMMPROJ": "gemma-3-4b-it-q4_0_s-mmproj-f16.gguf",
          "args": ["--ctx-size", "32768"],
          "np": ["--parallel", "4"]
        }
      }
    },
    "gemma3n": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.genericprep"
      },
      "quantFiles": {
        "q4": {
          "file": "gemma-3n-e4b-it-q4_0.gguf",
          "args": ["--ctx-size", "32768"],
          "np": ["--parallel", "4"]
        }
      }
    },
    "qwen": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.genericprep",
        "localPreset": true
      },
      "default": {
        "prompt": {
          "defSys": [false, "", "", false],
          "defPrep": [true, "{{MAIN_TL_INSTRUCTIONS}}", "user", false]
        },
        "model": {
          "delay": [false, 0.1],
          "llmbackend": "openai",
          "url": "http://localhost:8080/v1/chat/completions",
          "temperature": [true, 0],
          "top_p": [true, 0.8],
          "top_k": [true, 20],
          "min_p": [true, 0.0],
          "presence_penalty": [true, 1.5],
          "repeat_penalty": [true, 1.0],
          "model": [true, "qwen"]
        }
      },
      "quantFiles": {
        "q4": {
          "file": "qwen3-4b-instruct-2507-ud-q4_k_xl.gguf",
          "args": ["--ctx-size", "32768"],
          "np": ["--parallel", "4"]
        }
      }
    },
    "qwencoder": {
      "reasoningType": "instruct_only",
      "metadata": {
        "helptext_key": "models.genericprep"
      },
      "quantFiles": {
        "q8": {
          "file": "qwen2.5-coder-3b-q8_0.gguf",
          "args": ["--ctx-size", "32768"],
          "np": [""]
        }
      }
    }
  }
}
