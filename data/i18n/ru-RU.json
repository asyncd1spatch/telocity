{
  "m": {
    "lcli": {
      "userConfigNotFound": "Файл конфигурации пользователя не найден по пути {{ .UserConfigPath }}. Будет создан новый.",
      "cfgCreatedSuccessfully": "Файл конфигурации успешно создан.",
      "deletionConfirm": "Действие необратимо. Уверены, что хотите удалить? (y/N): ",
      "yN": "y",
      "redacted": "[REDACTED]",
      "deletionAborted": "Удаление отменено.",
      "a": "a",
      "q": "q"
    },
    "lllm": {
      "processingComplete": "Обработка этого файла уже завершена.",
      "anotherInstanceIsProcessing": "Другой экземпляр уже обрабатывает этот файл. Пожалуйста, подождите, пока он завершит работу, или удалите файл .lock.",
      "ctrlCPressed": "Нажата клавиша Ctrl+C. Завершение текущего батча и сохранение прогресса. Нажмите снова для принудительного выхода.",
      "ctrlCPressed2": "Запрос на завершение уже был отправлен. Подождите.",
      "quittingWithoutSaving": "Принудительный выход без сохранения прогресса.",
      "processedChunkOf": "Обработано куска {{ .Processed }} из {{ .Total }}",
      "progressSavedTerminating": "Прогресс сохранён. Завершаю.",
      "progressFileDeleted": "Файл прогресса для хэша {{ .Hash }} удалён.",
      "content": "\n--- Содержимое из: {{ .Filename }} ---",
      "filesMerged": "Файлы успешно объединены в: {{ .MergedFileName }}",
      "openingTag": "Открывающий тег",
      "closingTag": "Закрывающий тег",
      "context": "Контекст:",
      "textToTranslate": "Текст для перевода на {{ .LanguageTarget }}:",
      "generatingRequests": "Генерируются {{ .Count }} запросов для обработки пакета...",
      "sourceEmpty": "Исходный файл пуст или содержит только пробелы. Никакого вывода не сгенерировано.",
      "wroteEntries": "Успешно записано {{ .Count }} записей в {{ .TargetPath }}"
    },
    "c": {
      "cfg": {
        "cfgDeletedSuccessfully": "Файлы конфигурации успешно удалены.",
        "localeSuccessfullyChanged": "Локаль успешно изменена на {{ .Locale }}."
      },
      "models": {
        "fallback": "Общая настройка для любой API, совместимой с OpenAI. Требуется имя модели.",
        "genericprep": "Общая настройка, которая добавляет промпт к тексту пользователя.",
        "genericsys": "Общая настройка, использующая системный промпт.",
        "noHelp": "Для этой настройки недоступна помощь."
      },
      "avg": {
        "averageCharsPerLine": "Среднее количество символов (графем) на непустой строке: {{ .AvgChars }}",
        "averageBytesPerLine": "Среднее количество байт на непустой строке: {{ .AvgBytes }}"
      },
      "lu": {
        "preparingLaunch": "Подготовка запуска модели '{{ .ModelPreset }}' (тип: {{ .ModelType }}, квантизация: {{ .QuantReq }}).",
        "found": "Найдено: {{ .String }}",
        "executingCommand": "\nВыполняется команда: {{ .String }}\n",
        "llamaServerExit": "Процесс llama-server завершился с кодом {{ .ExitCode }}."
      },
      "rm": {
        "filesToDelete": "Следующие файлы прогресса будут удалены:",
        "filesDeletedSuccessfully": "Все файлы прогресса успешно удалены.",
        "filesToDeletePrompt": "\nВведите номера или диапазоны для удаления (например, `1,3-5`), `a` для всех, или `q` для отмены: ",
        "filesSelectedForDeletion": "\nФайлы выбраны для удаления:",
        "noValidSelectionsMade": "Не были сделаны корректные выборы. Отмена.",
        "noFilesToDelete": "Нет файлов прогресса, которые можно удалить."
      },
      "sp": {
        "fileSplitSuccess": "Успешно разбит файл: {{ .SourcePath }}",
        "partCreated": "  - Создано часть {{ .PartNumber }}: {{ .PartPath }}"
      },
      "st": {
        "blockExtracted": "Содержимое между дельтами извлечено.",
        "blockDeleted": "Содержимое между дельтами удалено.",
        "compressed": "Пустые строки сжаты.",
        "newlinesNormalized": "Содержимое файла нормализовано и сохранено."
      },
      "tc": {
        "availableModelsForDownload": "Доступные модели для загрузки: {{ .AvailableModels }}",
        "downloadingModelFiles": "Загрузка файлов модели для \"{{ .ModelName }}\"...",
        "writingFilesTo": "Запись файлов в {{ .StateDir }}...",
        "downloadSuccess": "Успешно загружены файлы для \"{{ .ModelName }}\":",
        "removedFailedWorker": "Удалён неудачный рабочий. Размер пула теперь {{ .PoolSize }}."
      },
      "ch": {
        "loadingSession": "Загрузка сессии из {{ .Path }}...",
        "creatingNewSession": "Создание новой сессии в {{ .Path }}...",
        "defaultSystemPrompt": "Вы являетесь полезным ассистентом.",
        "welcome": "Добро пожаловать в чат '{{ .ChatName }}'!",
        "typeHelp": "Введите сообщение или введите /help для команд.",
        "exiting": "Завершение сессии чата. До свидания!",
        "availableCommands": "Доступные команды:\n  /exit, /quit    - Завершить сессию чата.\n  /stats          - Показать статистику сессии (счётчик токенов и т.д.).\n  /forcegen       - Принудительно сгенерировать новый ответ из текущего диалога.\n  /delete <index> - Удалить сообщение на указанном индексе.\n  /browse         - Войти в интерактивный браузер сообщений.\n  /insert <path>  - Добавить текст или изображение в очередь для следующего сообщения.",
        "deletedMessage": "Удалено сообщение на индексе {{ .Index }}.",
        "imageQueued": "Изображение '{{ .FilePath }}' добавлено в очередь для следующего сообщения.",
        "textQueued": "Текст из '{{ .FilePath }}' добавлен в очередь для следующего сообщения.",
        "imageCountSuffix": " [+{{ .Count }} изображение(ов)]",
        "statsDisplay": "Настройка: {{ .Preset }} | Режим: {{ .Mode }} | Модель: {{ .Model }} | Сообщения: {{ .Messages }} | Контекст: {{ .Tokens }}/{{ .Limit }} ({{ .Usage }}%)",
        "exitedBrowseMode": "Выход из режима браузинга.",
        "viewingMessageHeader": "--- ПРОСМОТР СООБЩЕНИЯ {{ .Index }} ({{ .Role }}) ---",
        "pressAnyKeyToReturn": "--- Нажмите любую клавишу, чтобы вернуться в список ---",
        "browseModeHeader": "--- Режим браузинга ---",
        "browseModeInstructions": "Вверх/Вниз: Перемещение | Del: Удалить | Enter: Просмотреть | Esc/q: Выход",
        "statusBarTokens": " Токены: {{ .Total }}/{{ .Limit }} ({{ .Usage }}%)",
        "statusBarHelp": " Введите /help для команд ",
        "headerTitle": " Чат: {{ .SessionName }} ",
        "insertedFileHeader": "\n\n--- Содержимое из: {{ .FileName }} ---\n\n"
      }
    }
  },
  "e": {
    "lcli": {
      "unknownErrorOccurred": "Приложение столкнулось с неизвестной ошибкой.",
      "causePrefix": "Причина:",
      "unknownOption": "Неизвестный параметр: '{{ .Option }}'.",
      "unexpectedPositional": "Ожидаемый позиционный аргумент: '{{ .Argument }}'.",
      "missingValue": "Параметр '{{ .Option }}' не имеет значения.",
      "booleanWithValue": "Параметр '{{ .Option }}' не принимает значение.",
      "ambiguousOptionValue": "Значение параметра '{{ .Option }}' неоднозначно. Чтобы указать значение, начинающееся с дефиса, используйте '{{ .Option }}=<value>'.",

      "invalidOptionValue": "Неверное значение для параметра '{{ .Option }}'.",
      "commandNotImplemented": "Команда не реализована: {{ .CommandAlias }}.",
      "cfgCouldNotBeLoaded": "Файл конфигурации не может быть загружен из {{ .UserConfigPath }}.",
      "listFormatWidthWarning": "Предупреждение: недостаточно места для форматирования описания списка."
    },
    "v": {
      "invalidArgArray": "Неверный массив аргументов: {{ .OptionValue }}",
      "invalidChunkSize": "Неверный размер куска. Должен быть целым числом от 1 до 200000. Предоставлено: {{ .ChunkSize }}",
      "invalidBatchSize": "Неверный размер пакета. Должен быть целым числом от 1 до 64. Предоставлено: {{ .BatchSize }}",
      "invalidIndex": "Неверный lastIndex. Должно быть положительным целым числом. Предоставлено: {{ .Index }}",
      "invalidPrompt": "Предоставлен неверный промпт. Должен быть непустой строкой.",
      "invalidModel": "Неверное имя модели: {{ .Model }}",
      "invalidText": "Неверный текст: {{ .Text }}",
      "invalidURL": "Неверный URL: {{ .URL }}",
      "invalidURLScheme": "Неверная схема URL. Должна начинаться с http:// или https://. Предоставлено: {{ .URL }}",
      "invalidAPIKey": "Неверный API-ключ: {{ .APIKey }}",
      "invalidTemperatureRange": "Температура должна быть числом от 0.0 до 2.0.",
      "invalidTopPRange": "Top_p должен быть числом от 0.0 до 1.0.",
      "invalidMinPRange": "Min_p должен быть числом от 0.0 до 1.0.",
      "invalidTopKRange": "Top_k должен быть целым числом от 0 до 1000.",
      "invalidRepeat": "Штраф повторения должен быть числом от 1.0 до 2.0.",
      "invalidPenaltyRange": "Штраф частоты/наличия должен быть числом от -2.0 до 2.0.",
      "seedMustBePositiveInteger": "Seed должен быть положительным целым числом.",
      "invalidTruthiness": "Неверное значение истинности. Должно быть true, false, 1 или 0.",
      "invalidDelayValue": "Задержка должна быть неотрицательным числом в кортеже [логическое значение, значение].",
      "invalidImageArray": "Неверный входной массив изображений. Ожидается массив данных URI, но получено: {{ .Value }}",
      "invalidDataURI": "Неверный формат изображения. Ожидается строка data URI, начинающаяся с 'data:', но получено: {{ .Value }}",
      "unsupportedImageType": "Предупреждение: шаблон изображений {{ .Args }} не соответствует поддерживаемым файлам.",
      "unsupportedImageType2": "Пропускается неподдерживаемый тип изображения \"{{ .Ext }}\" для файла: {{ .Image }}",
      "missingImageExtension": "Не удалось определить тип изображения для файла '{{ .FilePath }}'. Пожалуйста, убедитесь, что файл имеет правильное расширение.",
      "imageNotFound": "Предупреждение: файл изображения не найден, пропускается: {{ .Image }}"
    },
    "lllm": {
      "undefinedParam": "Неопределённый набор параметров.",
      "reasoningNotSupported": "Модель не поддерживает рассуждение.",
      "invalidReasoningType": "Неверный тип рассуждения, повреждённая конфигурация JSON.",
      "promptMissing": "Для команды one-shot требуется промпт.",
      "fileNotFound": "Файл не найден: {{ .FilePath }}",
      "sourceRequired": "Требуется путь к источнику.",
      "sourceTargetRequired": "Требуются пути к источнику и целевому файлу.",
      "noFilesFound": "Нет файлов с расширением: .{{ .Extension }}",
      "targetFileExists": "Целевой путь уже существует: {{ .TargetPath }}",
      "sourceAndTargetMustBeDifferent": "Пути к источнику и целевому файлу должны быть разными.",
      "invalidFileSize": "Размер файла превышает максимальный лимит {{ .MAX_SIZE_MB }} МБ.",
      "emptyFile": "Файл пуст или содержит только пробелы.",
      "idleTimeOut": "Превышено время ожидания. Не получено данных от сервера.",
      "hardTimeOut": "Превышено твёрдое время ожидания. Запрос занял слишком много времени для завершения.",
      "tExceeded": "Превышено время ожидания",
      "unknownOpenAIError": "При работе с API произошла неизвестная ошибка.",
      "openaiApiError": "Ошибка вызова API с кодом {{ .Status }}: {{ .Message }}",
      "networkErrorOpenAI": "Сеть при вызове {{ .URL }}.",
      "networkErrorReason": " Причина: {{ .Code }}",
      "responseNull": "Тело ответа пустое",
      "streamEndedPrematurely": "Стрим завершился преждевременно без сигнала [DONE].",
      "badPromptConfig": "Некорректная конфигурация промпта. Требуется промпт.",
      "progressFileDoesNotExist": "Файл прогресса для хэша {{ .Hash }} не существует.",
      "llmAPICall": "Ошибка при вызове API LLM: ",
      "initializingBatch": "Ошибка при инициализации обработки пакета.",
      "failedLock": "Не удалось создать файл блокировки.",
      "failedToSaveProgress": "Не удалось сохранить прогресс.",
      "whileCalling_deleteProgressEntry": " при вызове deleteProgressEntry.",
      "stripNewLinesTypeError": "Вход должен быть строкой или массивом строк.",
      "invalidFormat": "Неверный формат '{{ .Format }}'. Поддерживаются форматы 'openai' и 'gemini'.",
      "jsonlGenError": "Произошла ошибка при генерации файла JSONL.",
      "idleTimeoutExceeded": "Превышено время ожидания"
    },
    "c": {
      "co": {
        "coError": "Предупреждение: не удалось загрузить модуль для команды {{ .Command }}. Пропускается генерация завершения."
      },
      "cfg": {
        "editorNotFound": "Не найдено переменной $EDITOR. Пожалуйста, установите переменную $EDITOR на предпочитаемый редактор.",
        "editorLaunchFailed": "Не удалось запустить редактор: {{ .ErrorMessage }}",
        "failedToWriteLocale": "Не удалось записать файл локали: {{ .ErrorMessage }}",
        "invalidLocale": "Неверная локаль: {{ .Lang }}."
      },
      "lu": {
        "undefinedLauncher": "Модель '{{ .ModelPreset }}' не настроена для локального запуска (отсутствуют 'quantFiles' или 'quantizationOrder').",
        "undefinedModelType": "Тип модели '{{ .ModelType }}' не найден для настройки '{{ .ModelPreset }}'.",
        "undefinedQuant": "Квантизация '{{ .QuantReq }}' не определена для настройки модели '{{ .ModelPreset }}'. Доступно: {{ .AvailableQuants }}.",
        "noModelFiles": "Не найдены файлы моделей GGUF на диске для настройки '{{ .ModelPreset }}' (тип: {{ .ModelType }}). Проверено квантизации: {{ .QuantList }}.",
        "failedToStart": "Не удалось запустить процесс llama-server: {{ .Error }}."
      },
      "mg": {
        "extensionRequired": "Требуется расширение файла. Используйте флаг -e или --extension."
      },
      "rm": {
        "unknownMode": "Неизвестный режим"
      },
      "sp": {
        "invalidSplitSize": "Неверный размер: {{ .Size }}. Должно быть положительным числом."
      },
      "st": {
        "delimiterPairRequired": "Требуются оба начальный и конечный дельтеры."
      },
      "tc": {
        "tokenizerDoesNotExist": "Для настройки '{{ .PresetName }}' не существует токенизатора.",
        "modelNotFoundForDownload": "Модель \"{{ .ModelName }}\" не найдена.",
        "failedToDownload": "Не удалось загрузить {{ .ModelUrl }}: {{ .Status }} {{ .StatusText }}",
        "modelDownloadError": "Ошибка при загрузке модели: {{ .ErrorMessage }}",
        "tokenizerLoadFailed": "Не удалось загрузить данные токенизатора для \"{{ .TokenizerName }}\". Убедитесь, что '{{ .JsonPath }}' и '{{ .ConfigPath }}' существуют и являются корректными JSON-файлами. Ошибка: {{ .Error }}",
        "tokenizerFilesNotFound": "Не удалось загрузить файлы токенизатора для {{ .TokenizerName }}",
        "unhandledWorkerError": "Необработанная ошибка в рабочем процессе токенизатора: {{ .Message }}",
        "poolShuttingDown": "Пул рабочих процессов завершает работу.",
        "poolShutdownJobCancelled": "Пул рабочих процессов завершает работу. Задача {{ .JobID }} отменена."
      },
      "ch": {
        "chatNameMissing": "Ошибка: требуется имя сессии чата.",
        "sessionLoadError": "Ошибка: не удалось загрузить или распарсить файл сессии по пути {{ .Path }}.",
        "chatLoopError": "Произошла непредвиденная ошибка во время сессии чата: {{ .Error }}",
        "contextLimitExceeded": "Превышено ограничение контекста {{ .Limit }} токенов (на данный момент {{ .Total }}). Используйте /delete <index> или /browse для удаления сообщений.",
        "invalidDeleteIndex": "Ошибка: неверный индекс сообщения. Пожалуйста, укажите число от 1 до {{ .Count }}.",
        "unknownCommand": "Ошибка: неизвестная команда '/{{ .Command }}'. Введите /help для списка команд.",
        "insertUsage": "Использование: /insert <путь_к_файлу>"
      }
    }
  },
  "help": {
    "generic": {
      "header": "telocity: инструмент для обработки текста в пакетах с использованием LLM.",
      "usage": "Использование: telocity <команда> [опции]",
      "commandHeader": "Команды:",
      "commandDescriptions": {
        "lu": "Запускает сервер llama с настройкой, заданной в конфигурации.",
        "tr": "Постепенно переводит файл по кускам.",
        "tf": "Применяет промпт преобразования к файлу по кускам.",
        "os": "Выполняет один промпт с возможным контекстом из файла.",
        "ch": "Запускает интерактивную сессию чата с LLM.",
        "bg": "Генерирует файл JSONL для обработки пакетов.",
        "st": "Удаляет или извлекает содержимое между дельтерами из файла.",
        "mg": "Объединяет несколько текстовых файлов в один файл.",
        "sp": "Разделяет большой файл на более мелкие части.",
        "avg": "Вычисляет среднее количество символов (графем) и байтов на непустой строке в файле.",
        "tc": "Подсчитывает количество токенов в файле с использованием специфического токенизатора модели.",
        "rm": "Удаляет файлы отслеживания прогресса для завершенных или зависших задач.",
        "cfg": "Управляет конфигурацией приложения."
      },
      "footer": "Для получения дополнительной информации о любой команде используйте `telocity <команда> --help`.",
      "globalOptionsHeader": "Глобальные опции:",
      "flags": {
        "version": "Показать версию приложения."
      }
    },
    "commands": {
      "lu": {
        "usage": "Использование: telocity launch [model_preset] [опции]",
        "description": "Находит наиболее подходящий локальный файл модели для заданной настройки и запускает сервер llama.cpp с соответствующими параметрами.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "reason": "Загрузить версию 'thinking' или 'reasoning' модели, если доступна.",
          "chat": "Запустить в режиме чата для одного пользователя (исключает аргументы параллельной обработки).",
          "quant": "Принудительно использовать конкретный уровень квантизации (например, 'q8', 'q6')."
        },
        "footer": "Доступные модели запуска:\n{{ .LaunchableModelList }}"
      },
      "avg": {
        "usage": "Использование: telocity avg <source_path>",
        "description": "Вычисляет среднее количество символов (графем) и байтов на непустой строке в файле."
      },
      "cfg": {
        "usage": "Использование: telocity cfg [опции]",
        "description": "Управляет конфигурацией приложения.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "edit": "Открыть файл конфигурации пользователя в предпочтительном редакторе.",
          "remove": "Удалить файлы конфигурации (подтверждение просьбы).",
          "lang": "Установить язык приложения."
        },
        "footer": "Поддерживаемые локали:\n{{ .LocaleList }}"
      },
      "rm": {
        "usage": "Использование: telocity rm <source_path> [опции]",
        "description": "Удаляет файлы отслеживания прогресса. Команда поддерживает три режима:\n\n- Позиционный (по умолчанию): Удаляет запись прогресса для одного исходного файла, идентифицированного по <source_path>.\n- Все (--all): Удаляет все отслеживаемые файлы прогресса.\n- Интерактивный (--interactive): Открывает меню, в котором перечислены все файлы прогресса, позволяя выбрать конкретные для удаления.\n\nИспользуйте --force (-f) для пропуска запросов на подтверждение.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "all": "Удалить все файлы прогресса.",
          "force": "Принудительное удаление без подтверждения.",
          "interactive": "Открыть интерактивное меню для выбора файлов прогресса для удаления."
        }
      },
      "mg": {
        "usage": "Использование: telocity mg <source_directory> [target_directory] -e <extension>",
        "description": "Рекурсивно находит и объединяет все файлы с заданным расширением из исходной директории в один файл в целевой директории (или в текущей директории, если не указано).",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "extension": "Расширение файла для поиска (обязательно)."
        }
      },
      "os": {
        "usage": "Использование: telocity os \"<prompt>\" [опции]",
        "description": "Выполняет один промпт против LLM. Может использовать контекст из файла (--file), стандартный ввод (stdin) и изображения (--image), затем передаёт вывод LLM в терминал.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "file": "Путь к текстовому файлу, который будет добавлен к промпту как контекст.",
          "image": "Путь к изображениям для визуального контекста. Поддерживает шаблоны и списки с запятыми (например, \"img1.jpg,*.png\"). Поддерживаются форматы: png, jpg/jpeg, gif, webp.",
          "params": "Выбрать настройку параметров модели (по умолчанию: {{ .DefaultModel }}).",
          "model": "Переопределить имя модели, указанное в настройке.",
          "url": "Переопределить URL конечной точки API.",
          "apikey": "Предоставить ключ API для запроса.",
          "reason": "Включить режим рассуждения для настроек, поддерживающих его."
        },
        "footer": "Доступные настройки:\n{{ .ModelParamList }}"
      },
      "sp": {
        "usage": "Использование: telocity sp <source_path> <target_directory> [опции]",
        "description": "Разделяет большой файл на более мелкие части по заданному размеру, обеспечивая, что строки не разбиваются.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "size": "Максимальный размер каждой части в мегабайтах (по умолчанию: {{ .Size }})."
        }
      },
      "st": {
        "usage": "Использование: telocity st <source_path> <target_path> [опции]",
        "description": "Удаляет или извлекает содержимое между заданными дельтерами из файла.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "startdelimiter": "Начальный дельтер.",
          "enddelimiter": "Конечный дельтер.",
          "params": "Использовать начальные/конечные дельтеры из настройки.",
          "extracttag": "Извлечь содержимое между дельтерами вместо удаления.",
          "compress": "Сжать пустые строки в выходе."
        },
        "footer": "Доступные настройки с тегами:\n{{ .ReasoningTagParamList }}"
      },
      "tc": {
        "usage": "Использование: telocity tc <source_path> [опции]",
        "description": "Подсчитывает количество токенов в файле с использованием токенизатора, специфичного для модели.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "params": "Настройка модели, чьи токенизаторы использовать (по умолчанию: {{ .DefaultModel }}).",
          "downloadmodel": "Загрузить файлы токенизатора для конкретной модели (например, 'qwen')."
        },
        "footer": "Доступные токенизаторы:\n{{ .TokenParamList }}"
      },
      "tf": {
        "usage": "Использование: telocity tf <source_path> <target_path> [опции]",
        "description": "Применяет промпт преобразования к исходному файлу, обрабатывая его по кускам. При использовании `--image` исходный файл должен содержать промпт для изображений. В этом режиме избегайте установки собственного `--chunksize`, чтобы обеспечить обработку промпта как единого блока.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "chunksize": "Количество строк на кусок (по умолчанию: {{ .ChunkSize }}).",
          "batchsize": "Количество кусков для обработки в пакете (по умолчанию: {{ .BatchSize }}).",
          "parallel": "Ограничение параллелизма (по умолчанию: {{ .Parallel }}).",
          "prompt": "Опциональное указание инструкции для добавления к содержимому исходного файла. Обычно не используется при использовании флага --image.",
          "image": "Путь к изображениям для визуального контекста. Поддерживает шаблоны и списки с запятыми (например, \"img1.jpg,*.png\"). Поддерживаются форматы: png, jpg/jpeg, gif, webp.",
          "sysprompt": "Установить кастомный системный промпт.",
          "params": "Выбрать настройку параметров модели (по умолчанию: {{ .DefaultModel }}).",
          "model": "Переопределить имя модели из настройки.",
          "url": "Переопределить URL конечной точки API.",
          "apikey": "Предоставить ключ API.",
          "wait": "Установить задержку между вызовами API.",
          "reason": "Включить режим рассуждения для настроек, поддерживающих его."
        },
        "footer": "Доступные настройки:\n{{ .ModelParamList }}"
      },
      "tr": {
        "usage": "Использование: telocity tr <source_path> <target_path> [опции]",
        "description": "Переводит файл из исходного языка в целевой язык, обрабатывая его по кускам.",
        "flags": {
          "help": "Показать это сообщение помощи.",
          "chunksize": "Количество строк на кусок (по умолчанию: {{ .ChunkSize }}).",
          "batchsize": "Количество кусков для обработки в пакете (по умолчанию: {{ .BatchSize }}).",
          "parallel": "Ограничение параллелизма (по умолчанию: {{ .Parallel }}).",
          "source": "Исходный язык (по умолчанию: \"{{ .SourceLanguage }}\").",
          "target": "Целевой язык (по умолчанию: \"{{ .TargetLanguage }}\").",
          "context": "Предоставить дополнительный контекст для перевода.",
          "params": "Выбрать настройку параметров модели (по умолчанию: {{ .DefaultModel }}).",
          "model": "Переопределить имя модели из настройки.",
          "url": "Переопределить URL конечной точки API.",
          "apikey": "Предоставить ключ API.",
          "wait": "Установить задержку между вызовами API.",
          "reason": "Включить режим рассуждения для настроек, поддерживающих его."
        },
        "footer": "Доступные настройки:\n{{ .ModelParamList }}"
      },
      "bg": {
        "usage": "Использование: telocity bg [опции] <source_file> <target_jsonl_file>",
        "description": "Генерирует файл JSONL для обработки пакетов переводов из исходного текстового файла.",
        "flags": {
          "format": "Формат выходного файла JSONL. Поддерживаются: 'openai', 'gemini'. (по умолчанию: openai)",
          "chunksize": "Количество строк на кусок/запрос. (по умолчанию: {{ .ChunkSize }})",
          "model": "Переопределяет модель, указанную в параметрах.",
          "params": "Настройка параметров для промпта и конфигурации модели. (по умолчанию: {{ .DefaultModel }})",
          "source": "Язык источника для промптов перевода.",
          "target": "Язык назначения для промптов перевода.",
          "context": "Дополнительный контекст, включаемый в промпт для каждого куска.",
          "reason": "Использовать вариант 'reasoning' выбранной настройки параметров модели.",
          "help": "Показать это сообщение помощи."
        },
        "footer": "\nДоступные наборы параметров:\n{{ .ModelParamList }}"
      },
      "ch": {
        "usage": "Использование: llm-cli ch [опции] <chat-name>",
        "description": "Запускает интерактивную сессию чата с LLM. История и настройки сессии сохраняются в файле, названном <chat-name>.json, в директории состояния приложения.",
        "flags": {
          "file": "Прикрепляет текстовый файл к первому сообщению новой сессии чата.",
          "image": "Прикрепляет один или несколько изображений (через запятую или шаблон) к первому сообщению новой сессии чата.",
          "model": "Переопределяет модель, указанную в настройке.",
          "params": "Настройка параметров для LLM. См. список ниже.",
          "context-limit": "Устанавливает максимальный лимит токенов для контекста чата.",
          "apikey": "Ключ API для сервиса LLM.",
          "url": "Переопределяет URL сервиса LLM.",
          "help": "Показать это сообщение помощи."
        },
        "footer": "Внутри чата введите /help, чтобы увидеть доступные интерактивные команды, такие как /exit, /stats, /delete, /browse и /insert.\n\nДоступные наборы параметров:\n{{ .ModelParamList }}"
      }
    }
  }
}
